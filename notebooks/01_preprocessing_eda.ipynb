{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing & Exploration\n",
    "\n",
    "#### Our goal is to prepare and understand the given dataset to build a solid foundation for the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Random seed set to: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 31)\n",
      "Index(['age', 'gender', 'ethnicity', 'education_level', 'income_level',\n",
      "       'employment_status', 'smoking_status', 'alcohol_consumption_per_week',\n",
      "       'physical_activity_minutes_per_week', 'diet_score',\n",
      "       'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
      "       'family_history_diabetes', 'hypertension_history',\n",
      "       'cardiovascular_history', 'bmi', 'waist_to_hip_ratio', 'systolic_bp',\n",
      "       'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol',\n",
      "       'ldl_cholesterol', 'triglycerides', 'glucose_fasting',\n",
      "       'glucose_postprandial', 'insulin_level', 'hba1c', 'diabetes_risk_score',\n",
      "       'diabetes_stage', 'diagnosed_diabetes'],\n",
      "      dtype='object')\n",
      "age                                     int64\n",
      "gender                                 object\n",
      "ethnicity                              object\n",
      "education_level                        object\n",
      "income_level                           object\n",
      "employment_status                      object\n",
      "smoking_status                         object\n",
      "alcohol_consumption_per_week            int64\n",
      "physical_activity_minutes_per_week      int64\n",
      "diet_score                            float64\n",
      "sleep_hours_per_day                   float64\n",
      "screen_time_hours_per_day             float64\n",
      "family_history_diabetes                 int64\n",
      "hypertension_history                    int64\n",
      "cardiovascular_history                  int64\n",
      "bmi                                   float64\n",
      "waist_to_hip_ratio                    float64\n",
      "systolic_bp                             int64\n",
      "diastolic_bp                            int64\n",
      "heart_rate                              int64\n",
      "cholesterol_total                       int64\n",
      "hdl_cholesterol                         int64\n",
      "ldl_cholesterol                         int64\n",
      "triglycerides                           int64\n",
      "glucose_fasting                         int64\n",
      "glucose_postprandial                    int64\n",
      "insulin_level                         float64\n",
      "hba1c                                 float64\n",
      "diabetes_risk_score                   float64\n",
      "diabetes_stage                         object\n",
      "diagnosed_diabetes                      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>...</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>glucose_fasting</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk_score</th>\n",
       "      <th>diabetes_stage</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>160</td>\n",
       "      <td>145</td>\n",
       "      <td>136</td>\n",
       "      <td>236</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>29.6</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Former</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>150</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>No Diabetes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "      <td>118</td>\n",
       "      <td>195</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>44.7</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Low</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.2</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>184</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.5</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Never</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>119</td>\n",
       "      <td>179</td>\n",
       "      <td>100</td>\n",
       "      <td>133</td>\n",
       "      <td>8.77</td>\n",
       "      <td>6.03</td>\n",
       "      <td>23.5</td>\n",
       "      <td>Pre-Diabetes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Upper-Middle</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>161</td>\n",
       "      <td>155</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>10.14</td>\n",
       "      <td>5.24</td>\n",
       "      <td>36.1</td>\n",
       "      <td>Pre-Diabetes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Current</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>159</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>189</td>\n",
       "      <td>8.96</td>\n",
       "      <td>7.04</td>\n",
       "      <td>34.2</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Current</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>132</td>\n",
       "      <td>98</td>\n",
       "      <td>116</td>\n",
       "      <td>172</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.90</td>\n",
       "      <td>26.7</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Current</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>109</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.99</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No Diabetes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender ethnicity education_level  income_level employment_status  \\\n",
       "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
       "1   48  Female     White      Highschool        Middle          Employed   \n",
       "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
       "3   74  Female     Black      Highschool           Low           Retired   \n",
       "4   46    Male     White        Graduate        Middle           Retired   \n",
       "5   46  Female     White      Highschool  Upper-Middle          Employed   \n",
       "6   75  Female     White        Graduate  Upper-Middle           Retired   \n",
       "7   62    Male     White    Postgraduate        Middle        Unemployed   \n",
       "8   42    Male     Black      Highschool  Lower-Middle          Employed   \n",
       "9   59  Female     White        Graduate        Middle          Employed   \n",
       "\n",
       "  smoking_status  alcohol_consumption_per_week  \\\n",
       "0          Never                             0   \n",
       "1         Former                             1   \n",
       "2          Never                             1   \n",
       "3          Never                             0   \n",
       "4          Never                             1   \n",
       "5          Never                             2   \n",
       "6          Never                             0   \n",
       "7        Current                             1   \n",
       "8        Current                             1   \n",
       "9        Current                             3   \n",
       "\n",
       "   physical_activity_minutes_per_week  diet_score  ...  hdl_cholesterol  \\\n",
       "0                                 215         5.7  ...               41   \n",
       "1                                 143         6.7  ...               55   \n",
       "2                                  57         6.4  ...               66   \n",
       "3                                  49         3.4  ...               50   \n",
       "4                                 109         7.2  ...               52   \n",
       "5                                 124         9.0  ...               61   \n",
       "6                                  53         9.2  ...               46   \n",
       "7                                  75         4.1  ...               49   \n",
       "8                                 114         6.7  ...               33   \n",
       "9                                  86         8.2  ...               52   \n",
       "\n",
       "   ldl_cholesterol  triglycerides  glucose_fasting  glucose_postprandial  \\\n",
       "0              160            145              136                   236   \n",
       "1               50             30               93                   150   \n",
       "2               99             36              118                   195   \n",
       "3               79            140              139                   253   \n",
       "4              125            160              137                   184   \n",
       "5              119            179              100                   133   \n",
       "6              161            155              101                   100   \n",
       "7              159            120              110                   189   \n",
       "8              132             98              116                   172   \n",
       "9              103            104               76                   109   \n",
       "\n",
       "   insulin_level  hba1c  diabetes_risk_score  diabetes_stage  \\\n",
       "0           6.36   8.18                 29.6          Type 2   \n",
       "1           2.00   5.63                 23.0     No Diabetes   \n",
       "2           5.07   7.51                 44.7          Type 2   \n",
       "3           5.28   9.03                 38.2          Type 2   \n",
       "4          12.74   7.20                 23.5          Type 2   \n",
       "5           8.77   6.03                 23.5    Pre-Diabetes   \n",
       "6          10.14   5.24                 36.1    Pre-Diabetes   \n",
       "7           8.96   7.04                 34.2          Type 2   \n",
       "8           5.70   6.90                 26.7          Type 2   \n",
       "9           4.49   4.99                 30.0     No Diabetes   \n",
       "\n",
       "   diagnosed_diabetes  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   0  \n",
       "6                   0  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/diabetes_dataset.csv')\n",
    "print(df.shape)\n",
    "print(df.columns) # Display column names (our features)\n",
    "print(df.dtypes)\n",
    "df.head(10) # Display first 10 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cleaning Process\n",
    "\n",
    "Start by first displaying the dataset before any changes are applied to it. Our provided [dataset](https://www.kaggle.com/datasets/mohankrishnathalla/diabetes-health-indicators-dataset/data) is already preprocessed, clean, and ready for models to start working with. However, we will still go through with cleaning process if we plan to add anymore future datasets. There is only one issue, specifically, the feature *diabetes_stages* is unneeded for our prediction model and basically gives away the answer.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset before cleaning:\n",
      "age                                      Mean:   50.120 | Median:   50.000\n",
      "alcohol_consumption_per_week             Mean:    2.004 | Median:    2.000\n",
      "physical_activity_minutes_per_week       Mean:  118.912 | Median:  100.000\n",
      "diet_score                               Mean:    5.995 | Median:    6.000\n",
      "sleep_hours_per_day                      Mean:    6.998 | Median:    7.000\n",
      "screen_time_hours_per_day                Mean:    5.996 | Median:    6.000\n",
      "family_history_diabetes                  Mean:    0.219 | Median:    0.000\n",
      "hypertension_history                     Mean:    0.251 | Median:    0.000\n",
      "cardiovascular_history                   Mean:    0.079 | Median:    0.000\n",
      "bmi                                      Mean:   25.613 | Median:   25.600\n",
      "waist_to_hip_ratio                       Mean:    0.856 | Median:    0.860\n",
      "systolic_bp                              Mean:  115.800 | Median:  116.000\n",
      "diastolic_bp                             Mean:   75.232 | Median:   75.000\n",
      "heart_rate                               Mean:   69.633 | Median:   70.000\n",
      "cholesterol_total                        Mean:  185.978 | Median:  186.000\n",
      "hdl_cholesterol                          Mean:   54.043 | Median:   54.000\n",
      "ldl_cholesterol                          Mean:  103.000 | Median:  102.000\n",
      "triglycerides                            Mean:  121.463 | Median:  121.000\n",
      "glucose_fasting                          Mean:  111.117 | Median:  111.000\n",
      "glucose_postprandial                     Mean:  160.035 | Median:  160.000\n",
      "insulin_level                            Mean:    9.061 | Median:    8.790\n",
      "hba1c                                    Mean:    6.521 | Median:    6.520\n",
      "diabetes_risk_score                      Mean:   30.222 | Median:   29.000\n",
      "diagnosed_diabetes                       Mean:    0.600 | Median:    1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset before cleaning:\")\n",
    "for column in df.columns:\n",
    "    if np.issubdtype(df[column].dtype, np.number):\n",
    "        print(f\"{column:<40} Mean: {df[column].mean():>8.3f} | Median: {df[column].median():>8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Before:   0 null\n",
      "(100000, 31)\n",
      "Total After:    0 null\n",
      "(88637, 30)\n"
     ]
    }
   ],
   "source": [
    "# Handling Null Values (empty records)\n",
    "df_null = df.isnull() # bool\n",
    "total_null = df_null.sum().sum() # count\n",
    "\n",
    "print(f\"Total Before:   {total_null} null\") # Summing up null values for each column before handling\n",
    "print(df.shape)\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Handling Outliers\n",
    "exclude_columns = ['family_history_diabetes','hypertension_history','cardiovascular_history','diagnosed_diabetes'] # Categorical columns to exclude (These are True/False binary values)\n",
    "for col in exclude_columns:\n",
    "    df_cleaned[col] = df_cleaned[col].clip(0,1) # reassigns any outliers to the closest bounds (0 or 1)\n",
    "\n",
    "allowed_columns = df_cleaned.select_dtypes(include=[np.number]).columns.difference(exclude_columns) # columns to check for outliers\n",
    "\n",
    "# Using IQR https://www.kaggle.com/code/aman2626786/outlier-removal-using-iqr-method\n",
    "# This removes around 16k records from original 100k records\n",
    "for col in allowed_columns:\n",
    "    p25 = df_cleaned[col].quantile(0.25)\n",
    "    p75 = df_cleaned[col].quantile(0.75)\n",
    "    iqr = p75 - p25\n",
    "    lower_bound = p25 - 1.5 * iqr\n",
    "    upper_bound = p75 + 1.5 * iqr\n",
    "    df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)] # Remove outliers\n",
    "\n",
    "# Handling duplicate and empty records\n",
    "df_cleaned = df_cleaned.drop_duplicates().dropna().drop('diabetes_stage', axis=1) # Drop duplicates, empty records, and 'diabetes_stage' column\n",
    "\n",
    "\n",
    "for column in df_cleaned.columns:\n",
    "    if df_cleaned[column].isnull().sum() > 0: # Check column datatypes if there exists null values\n",
    "        if df_cleaned[column].dtype in [np.float64, np.int64]: # Numerical variables\n",
    "            print(f\"{column} contains {df_cleaned[column].isnull().sum()} null values.\")\n",
    "            df_cleaned[column] = df_cleaned[column].fillna(df_cleaned[column].median())\n",
    "        else:\n",
    "            df_cleaned[column] = df_cleaned[column].fillna(\"UNKNOWN\") # Categorical variables\n",
    "\n",
    "cleandf_null = df_cleaned.isnull() # bool\n",
    "\n",
    "print(f\"Total After:    {cleandf_null.sum().sum()} null\") # Summing up null values for each column\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after cleaning:\n",
      "age                                      Mean:   49.764 | Median:   50.000\n",
      "gender                                   Mean:    0.518 | Median:    0.000\n",
      "ethnicity                                Mean:    2.532 | Median:    3.000\n",
      "education_level                          Mean:    1.001 | Median:    1.000\n",
      "income_level                             Mean:    2.499 | Median:    3.000\n",
      "employment_status                        Mean:    0.697 | Median:    0.000\n",
      "smoking_status                           Mean:    1.399 | Median:    2.000\n",
      "alcohol_consumption_per_week             Mean:    1.979 | Median:    2.000\n",
      "physical_activity_minutes_per_week       Mean:  110.947 | Median:   97.000\n",
      "diet_score                               Mean:    6.026 | Median:    6.000\n",
      "sleep_hours_per_day                      Mean:    7.000 | Median:    7.000\n",
      "screen_time_hours_per_day                Mean:    5.966 | Median:    6.000\n",
      "family_history_diabetes                  Mean:    0.211 | Median:    0.000\n",
      "hypertension_history                     Mean:    0.249 | Median:    0.000\n",
      "cardiovascular_history                   Mean:    0.078 | Median:    0.000\n",
      "bmi                                      Mean:   25.563 | Median:   25.600\n",
      "waist_to_hip_ratio                       Mean:    0.856 | Median:    0.860\n",
      "systolic_bp                              Mean:  115.484 | Median:  115.000\n",
      "diastolic_bp                             Mean:   75.194 | Median:   75.000\n",
      "heart_rate                               Mean:   69.815 | Median:   70.000\n",
      "cholesterol_total                        Mean:  185.296 | Median:  185.000\n",
      "hdl_cholesterol                          Mean:   54.135 | Median:   54.000\n",
      "ldl_cholesterol                          Mean:  102.194 | Median:  101.000\n",
      "triglycerides                            Mean:  120.748 | Median:  121.000\n",
      "glucose_fasting                          Mean:  111.022 | Median:  111.000\n",
      "glucose_postprandial                     Mean:  159.903 | Median:  160.000\n",
      "insulin_level                            Mean:    8.987 | Median:    8.750\n",
      "hba1c                                    Mean:    6.517 | Median:    6.520\n",
      "diabetes_risk_score                      Mean:   30.127 | Median:   28.900\n",
      "diabetes_stage                           Mean:    3.117 | Median:    4.000\n",
      "diagnosed_diabetes                       Mean:    0.600 | Median:    1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset after cleaning:\")\n",
    "for column in df_cleaned.columns:\n",
    "    if np.issubdtype(df_cleaned[column].dtype, np.number):\n",
    "        print(f\"{column:<40} Mean: {df_cleaned[column].mean():>8.3f} | Median: {df_cleaned[column].median():>8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Encoding \n",
    "\n",
    "To allow our dataset to become understandable to machine learning algorithms, we must encode the categorical objects in our dataset. Categorical variables/objects are often data types that these algorithms cannot understand (e.g., strings, descriptive information), there are two different types that exist: *Ordinal* and *Nominal*.\n",
    "\n",
    "**Ordinal Data** - \n",
    "    Can be described as values that contain an \"order\" or a \"hierarchy\". For example, we can see this for feature *education_level*, as we grown up experiencing this as we progressed from all elementary school to university.\n",
    "\n",
    "**Nominal Data** - \n",
    "    Can be decsribed as values that contain no order. For example, we see this with feature *gender*, where the options are Man or Female and there is no order between the two.\n",
    "    \n",
    "Encoding properly is vital as to our prediction model stripping away bias and relationships, while also providing additional information. There are several approaches to do this, however we decided to select: *One Hot Encoding* and *Ordinal Encoding*:\n",
    "\n",
    "| Column Name         | Data Type | Categorical Type | Encoding Approach\n",
    "|----------------------|------------|------------|------------|\n",
    "| gender               | object     | nominal  | one hot encoding\n",
    "| ethnicity            | object     | nominal  | one hot encoding\n",
    "| education_level      | object     | ordinal  | ordinal encoding\n",
    "| income_level         | object     | ordinal  | ordinal encoding\n",
    "| employment_status    | object     | nominal  | one hot encoding\n",
    "| smoking_status       | object     | ordinal  | ordinal encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "nominal_columns = ['gender', 'ethnicity', 'employment_status']\n",
    "ordinal_columns = ['education_level', 'income_level', 'smoking_status']\n",
    "ordinal_categories = [\n",
    "    ['No formal', 'Highschool', 'Graduate', 'Postgraduate'],  # education_level\n",
    "    ['Low', 'Lower-Middle', 'Middle', 'Upper-Middle', 'High'],  # income_level\n",
    "    ['Never', 'Former', 'Current']  # smoking_status\n",
    "]\n",
    "\n",
    "# One Hot Encoding\n",
    "df_feature = df_cleaned.copy()\n",
    "df_feature = pd.get_dummies(df_feature, columns=nominal_columns,drop_first=True,dtype=int)\n",
    "\n",
    "# Ordinal Encoding\n",
    "encoder = OrdinalEncoder(categories=ordinal_categories)\n",
    "df_feature[ordinal_columns] = encoder.fit_transform(df_feature[ordinal_columns])\n",
    "\n",
    "#df_feature will be used on forward instead of df_clean btw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploratory Data Analysis\n",
    "binning\n",
    " -- age \n",
    " -- white vs minorities\n",
    " -- educated vs uneducated (high school degree vs higher education)\n",
    " -- smoked vs never smoked\n",
    " -- alc vs no alc\n",
    "ratios\n",
    "differences\n",
    "\n",
    "MULTICOLLINEARITY\n",
    "\n",
    "notes:\n",
    "     main indicators - loss in weight and high blood sugar\n",
    "                     - high bmi\n",
    "                     - physical and shit diet\n",
    "                     -  low education w/ low income\n",
    "                     - type 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '51-60'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m features = df_feature.columns.difference([\u001b[33m'\u001b[39m\u001b[33mdiagnosed_diabetes\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;66;03m# features to compare to\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m features: \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     corr_val = \u001b[43mdf_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdiagnosed_diabetes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m  corr_val > \u001b[32m0.3\u001b[39m: \u001b[38;5;66;03m# parse for moderate / strong correlation\u001b[39;00m\n\u001b[32m     10\u001b[39m         strong_corr[col] = corr_val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pdr-ai/venv/lib/python3.13/site-packages/pandas/core/series.py:2987\u001b[39m, in \u001b[36mSeries.corr\u001b[39m\u001b[34m(self, other, method, min_periods)\u001b[39m\n\u001b[32m   2984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(this) == \u001b[32m0\u001b[39m:\n\u001b[32m   2985\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m this_values = \u001b[43mthis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2988\u001b[39m other_values = other.to_numpy(dtype=\u001b[38;5;28mfloat\u001b[39m, na_value=np.nan, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mspearman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkendall\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(method):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pdr-ai/venv/lib/python3.13/site-packages/pandas/core/base.py:641\u001b[39m, in \u001b[36mIndexOpsMixin.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    554\u001b[39m \u001b[33;03mA NumPy ndarray representing the values in this Series or Index.\u001b[39;00m\n\u001b[32m    555\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    638\u001b[39m \u001b[33;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.dtype, ExtensionDtype):\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m kwargs:\n\u001b[32m    643\u001b[39m     bad_keys = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs.keys()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pdr-ai/venv/lib/python3.13/site-packages/pandas/core/arrays/base.py:568\u001b[39m, in \u001b[36mExtensionArray.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_numpy\u001b[39m(\n\u001b[32m    540\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    541\u001b[39m     dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    542\u001b[39m     copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    543\u001b[39m     na_value: \u001b[38;5;28mobject\u001b[39m = lib.no_default,\n\u001b[32m    544\u001b[39m ) -> np.ndarray:\n\u001b[32m    545\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[33;03m    Convert to a NumPy ndarray.\u001b[39;00m\n\u001b[32m    547\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    566\u001b[39m \u001b[33;03m    numpy.ndarray\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m     result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    570\u001b[39m         result = result.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pdr-ai/venv/lib/python3.13/site-packages/pandas/core/arrays/_mixins.py:81\u001b[39m, in \u001b[36mravel_compat.<locals>.method\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(meth)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     flags = \u001b[38;5;28mself\u001b[39m._ndarray.flags\n\u001b[32m     84\u001b[39m     flat = \u001b[38;5;28mself\u001b[39m.ravel(\u001b[33m\"\u001b[39m\u001b[33mK\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pdr-ai/venv/lib/python3.13/site-packages/pandas/core/arrays/categorical.py:1692\u001b[39m, in \u001b[36mCategorical.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   1686\u001b[39m ret = take_nd(\u001b[38;5;28mself\u001b[39m.categories._values, \u001b[38;5;28mself\u001b[39m._codes)\n\u001b[32m   1687\u001b[39m \u001b[38;5;66;03m# When we're a Categorical[ExtensionArray], like Interval,\u001b[39;00m\n\u001b[32m   1688\u001b[39m \u001b[38;5;66;03m# we need to ensure __array__ gets all the way to an\u001b[39;00m\n\u001b[32m   1689\u001b[39m \u001b[38;5;66;03m# ndarray.\u001b[39;00m\n\u001b[32m   1690\u001b[39m \n\u001b[32m   1691\u001b[39m \u001b[38;5;66;03m# `take_nd` should already make a copy, so don't force again.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1692\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '51-60'"
     ]
    }
   ],
   "source": [
    "# Correlation between features and diabetes_diagnosis\n",
    "strong_corr = {} # save positive values here\n",
    "inv_strong_corr = {} # save negative values here\n",
    "# We can setup more bins in the feature for future datasets\n",
    "\n",
    "features = df_feature.columns.difference(['diagnosed_diabetes']) # features to compare to\n",
    "for col in features: \n",
    "    corr_val = df_feature[col].corr(df_feature['diagnosed_diabetes'])\n",
    "    if  corr_val > 0.3: # parse for moderate / strong correlation\n",
    "        strong_corr[col] = corr_val\n",
    "        print(f\"{col}: {corr_val}\")\n",
    "\n",
    "    elif corr_val < -0.3: # inverse\n",
    "        strong_corr[col] = corr_val\n",
    "        print(f\"{col}: {corr_val}\")\n",
    "\n",
    "# print(df_feature['physical_activity_minutes_per_week'].corr(df_feature['diagnosed_diabetes'])) # just checking this specific feature\n",
    "\n",
    "\n",
    "# AGE DISTRIBUTION BY DIABETES STATUS\n",
    "# Create age bins and labels\n",
    "age_bins = [0, 20, 30, 40, 50, 60, 100]\n",
    "age_labels = ['≤20', '21-30', '31-40', '41-50', '51-60', '60+']\n",
    "\n",
    "# Initialize counters\n",
    "age_no_diabetes = [0, 0, 0, 0, 0, 0]\n",
    "age_diabetes = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# Count by age group and diabetes status\n",
    "for index, row in df_feature.iterrows():\n",
    "    age = row['age']\n",
    "    diabetes_diagnosis = row['diabetes_diagnosis']\n",
    "\n",
    "    # Bin age\n",
    "    if age <= 20:\n",
    "        age_group = 0\n",
    "    elif age <= 30:\n",
    "        age_group = 1\n",
    "    elif age <= 40:\n",
    "        age_group = 2\n",
    "    elif age <= 50:\n",
    "        age_group = 3\n",
    "    elif age <= 60:\n",
    "        age_group = 4\n",
    "    else:\n",
    "        age_group = 5\n",
    "\n",
    "    if diabetes_diagnosis == 1:\n",
    "        age_diabetes[age_group] += 1\n",
    "    else:\n",
    "        age_no_diabetes[age_group] += 1\n",
    "\n",
    "        # TODO: Plot Bar Graph\n",
    "\n",
    "# Education vs No Education\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Income Level\n",
    "\n",
    "# Smoking Status\n",
    "\n",
    "# Family History\n",
    "\n",
    "# bmi glucose hba1c histograms\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 ?\n",
    "### Same notebook or a separate one?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pdr-ai)",
   "language": "python",
   "name": "pdr-ai-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
